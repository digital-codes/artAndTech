{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f41fa55c",
   "metadata": {},
   "source": [
    "Basic NLTK Example from https://www.dataknowsall.com/bowtfidf.html\n",
    "\n",
    "with some additions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7e3e83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/kugel/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# random features\n",
    "from random import sample\n",
    "\n",
    "from string import punctuation\n",
    "\n",
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import SyllableTokenizer\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import LegalitySyllableTokenizer\n",
    "import nltk\n",
    "nltk.download(\"punkt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076edd0d",
   "metadata": {},
   "source": [
    "A corpus is casically a list of sentences. YOu can create your own or use an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "51807d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"Tune a hyperparameter.\",\n",
    "    \"You can tune a piano but you cannot tune a fish.\",\n",
    "    \"Fish who eat fish, catch fish.\",\n",
    "    \"People can tune a fish or a hyperparameter.\",\n",
    "    \"It is hard to catch fish and tune it.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4daa4e13",
   "metadata": {},
   "source": [
    "We do some standard text processing first\n",
    "First thing is to get the occurancies of all words in all lines. We use the count vectorizer to do this. Stop words are dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba11382e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>catch</th>\n",
       "      <th>eat</th>\n",
       "      <th>fish</th>\n",
       "      <th>hard</th>\n",
       "      <th>hyperparameter</th>\n",
       "      <th>people</th>\n",
       "      <th>piano</th>\n",
       "      <th>tune</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   catch  eat  fish  hard  hyperparameter  people  piano  tune\n",
       "0      0    0     0     0               1       0      0     1\n",
       "1      0    0     1     0               0       0      1     2\n",
       "2      1    1     3     0               0       0      0     0\n",
       "3      0    0     1     0               1       1      0     1\n",
       "4      1    0     1     1               0       0      0     1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start with CountVectorizer which creates a BoW\n",
    "vectorizer = CountVectorizer(stop_words='english') \n",
    "X = vectorizer.fit_transform(corpus) \n",
    "pd.DataFrame(X.A, columns=vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8adbad6",
   "metadata": {},
   "source": [
    "The version above shows the actual occurancies. Now we use another vectorizer, which uses a different metric. We can configure this TfIdf (Term frequency-inverse document frequency, see e.g. [here](https://towardsdatascience.com/tf-idf-simplified-aba19d5f5530) ) vectorizer in two modes (\"use_idf\" fasle or true). False doens not consider the document frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a01c1bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>catch</th>\n",
       "      <th>eat</th>\n",
       "      <th>fish</th>\n",
       "      <th>hard</th>\n",
       "      <th>hyperparameter</th>\n",
       "      <th>people</th>\n",
       "      <th>piano</th>\n",
       "      <th>tune</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.302</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   catch    eat   fish  hard  hyperparameter  people  piano   tune\n",
       "0  0.000  0.000  0.000   0.0           0.707     0.0  0.000  0.707\n",
       "1  0.000  0.000  0.408   0.0           0.000     0.0  0.408  0.816\n",
       "2  0.302  0.302  0.905   0.0           0.000     0.0  0.000  0.000\n",
       "3  0.000  0.000  0.500   0.0           0.500     0.5  0.000  0.500\n",
       "4  0.500  0.000  0.500   0.5           0.000     0.0  0.000  0.500"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words='english', use_idf=False) \n",
    "X = vectorizer.fit_transform(corpus) \n",
    "df = pd.DataFrame(np.round(X.A,3), columns=vectorizer.get_feature_names_out())\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010dc0b6",
   "metadata": {},
   "source": [
    "use_idf = True uses the iverse document frequency, which favors words which are used in fewer lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c1bf3edf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>catch</th>\n",
       "      <th>eat</th>\n",
       "      <th>fish</th>\n",
       "      <th>hard</th>\n",
       "      <th>hyperparameter</th>\n",
       "      <th>people</th>\n",
       "      <th>piano</th>\n",
       "      <th>tune</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.622</td>\n",
       "      <td>0.701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.380</td>\n",
       "      <td>0.471</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.534</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   catch    eat   fish   hard  hyperparameter  people  piano   tune\n",
       "0  0.000  0.000  0.000  0.000           0.820   0.000  0.000  0.573\n",
       "1  0.000  0.000  0.350  0.000           0.000   0.000  0.622  0.701\n",
       "2  0.380  0.471  0.796  0.000           0.000   0.000  0.000  0.000\n",
       "3  0.000  0.000  0.373  0.000           0.534   0.661  0.000  0.373\n",
       "4  0.534  0.000  0.373  0.661           0.000   0.000  0.000  0.373"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inverse vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words='english', use_idf=True) \n",
    "X = vectorizer.fit_transform(corpus) \n",
    "df = pd.DataFrame(np.round(X.A,3), columns=vectorizer.get_feature_names_out())\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e381d31",
   "metadata": {},
   "source": [
    "Instead of counting words (somehow) we can also split lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3febe531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words:  ['Tune', 'a', 'hyperparameter', '.', 'You', 'can', 'tune', 'a', 'piano', 'but', 'you', 'can', 'not', 'tune', 'a', 'fish', '.', 'Fish', 'who', 'eat', 'fish', ',', 'catch', 'fish', '.', 'People', 'can', 'tune', 'a', 'fish', 'or', 'a', 'hyperparameter', '.', 'It', 'is', 'hard', 'to', 'catch', 'fish', 'and', 'tune', 'it', '.']\n",
      "Syllables in sentence:  [['Tu', 'ne'], ['a'], ['hy', 'per', 'pa', 'ra', 'me', 'ter'], ['.'], ['Yo', 'u'], ['can'], ['tu', 'ne'], ['a'], ['pia', 'no'], ['but'], ['yo', 'u'], ['can'], ['not'], ['tu', 'ne'], ['a'], ['fish'], ['.'], ['Fish'], ['who'], ['eat'], ['fish'], [','], ['catch'], ['fish'], ['.'], ['Peo', 'ple'], ['can'], ['tu', 'ne'], ['a'], ['fish'], ['or'], ['a'], ['hy', 'per', 'pa', 'ra', 'me', 'ter'], ['.'], ['It'], ['is'], ['hard'], ['to'], ['catch'], ['fish'], ['and'], ['tu', 'ne'], ['it'], ['.']]\n"
     ]
    }
   ],
   "source": [
    "# tokenize into words\n",
    "w = word_tokenize(\" \".join(corpus))\n",
    "print(\"Words: \",w)\n",
    "# syllables\n",
    "result = [SSP.tokenize(token) for token in word_tokenize(\" \".join(corpus))]\n",
    "print(\"Syllables in sentence: \",result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16576fc",
   "metadata": {},
   "source": [
    "We can also tokenize words into sylables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f9493162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Syllables:  ['jus', 'ti', 'fi', 'ca', 'tion']\n"
     ]
    }
   ],
   "source": [
    "# sylable, single word\n",
    "SSP = SyllableTokenizer()\n",
    "s = SSP.tokenize('justification')\n",
    "print(\"Syllables: \",s)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8ab64f",
   "metadata": {},
   "source": [
    "### After these basic examples we try to create lyrics\n",
    "A HAIKU A haiku is defined to have 3 lines with any number of words, provided the number of sylables is 5, 7 and 5 in the 3 lines.\n",
    "\n",
    "We start with the same corpus, but you may use some other text line or an NLTK sample corpus (check NLTK website)\n",
    "First thing to do here is to remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "070b99cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:  Tune a hyperparameter You can tune a piano but you cannot tune a fish Fish who eat fish  catch fish People can tune a fish or a hyperparameter It is hard to catch fish and tune it \n"
     ]
    }
   ],
   "source": [
    "# combine into single string and replace all punction with \"\"\n",
    "text = \"\".join(corpus)\n",
    "for p in punctuation:\n",
    "    text = text.replace(p,\" \")\n",
    "    \n",
    "print(\"Text: \",text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314f620f",
   "metadata": {},
   "source": [
    "Now we split into words (similar to example above) and create a dict with the number of sylables for each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c45791cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words:  ['Tune', 'a', 'hyperparameter', 'You', 'can', 'tune', 'a', 'piano', 'but', 'you', 'can', 'not', 'tune', 'a', 'fish', 'Fish', 'who', 'eat', 'fish', 'catch', 'fish', 'People', 'can', 'tune', 'a', 'fish', 'or', 'a', 'hyperparameter', 'It', 'is', 'hard', 'to', 'catch', 'fish', 'and', 'tune', 'it']\n",
      "Wdict:  {'Tune': 2, 'a': 1, 'hyperparameter': 6, 'You': 2, 'can': 1, 'tune': 2, 'piano': 2, 'but': 1, 'you': 2, 'not': 1, 'fish': 1, 'Fish': 1, 'who': 1, 'eat': 1, 'catch': 1, 'People': 2, 'or': 1, 'It': 1, 'is': 1, 'hard': 1, 'to': 1, 'and': 1, 'it': 1}\n"
     ]
    }
   ],
   "source": [
    "# tokenize into words\n",
    "words = word_tokenize(text)\n",
    "print(\"Words: \",words)\n",
    "\n",
    "# create dict with words and number of sylables\n",
    "wdict = {}\n",
    "for w in words:\n",
    "    if not w in wdict:\n",
    "        wdict[w] = len(SSP.tokenize(w))\n",
    "\n",
    "print(\"Wdict: \",wdict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f0da78",
   "metadata": {},
   "source": [
    "Lets take a random sample from our dict (this will generate different results on every run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "37629b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['It', 'not', 'eat', 'can', 'you']\n",
      "It: 1 sylables\n",
      "not: 1 sylables\n",
      "eat: 1 sylables\n",
      "can: 1 sylables\n",
      "you: 2 sylables\n"
     ]
    }
   ],
   "source": [
    "n = 5\n",
    "rwords = sample(list(wdict.keys()), n)\n",
    "print(rwords)\n",
    "for r in rwords:\n",
    "    print(f\"{r}: {wdict[r]} sylables\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb63957",
   "metadata": {},
   "source": [
    "### Up to you to create lines with the appropriate number of sylables for the haiku\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
